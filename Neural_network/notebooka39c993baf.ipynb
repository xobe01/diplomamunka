{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-02T21:17:44.685559Z",
     "iopub.status.busy": "2023-12-02T21:17:44.685100Z",
     "iopub.status.idle": "2023-12-02T21:17:44.826107Z",
     "shell.execute_reply": "2023-12-02T21:17:44.825104Z",
     "shell.execute_reply.started": "2023-12-02T21:17:44.685467Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=7, micro=6, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T21:17:44.833497Z",
     "iopub.status.busy": "2023-12-02T21:17:44.831081Z",
     "iopub.status.idle": "2023-12-02T21:17:54.600923Z",
     "shell.execute_reply": "2023-12-02T21:17:54.599774Z",
     "shell.execute_reply.started": "2023-12-02T21:17:44.833450Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file '<unprintable file name>': [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'import tensorflow as tf\\nfrom tensorflow.keras.utils import normalize\\nimport os\\nimport cv2\\nfrom PIL import Image\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.optimizers import Adam\\nimport glob\\n'' returned non-zero exit status 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-74ec1e31ce6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'python'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'–version'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'import tensorflow as tf\\nfrom tensorflow.keras.utils import normalize\\nimport os\\nimport cv2\\nfrom PIL import Image\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.optimizers import Adam\\nimport glob\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2360\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2361\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2362\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2363\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[1;34m(line, cell)\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;31m# write a basic docstring:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<C:\\Users\\ungbo\\anaconda3\\lib\\site-packages\\decorator.py:decorator-gen-111>\u001b[0m in \u001b[0;36mshebang\u001b[1;34m(self, line, cell)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\script.py\u001b[0m in \u001b[0;36mshebang\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command 'b'import tensorflow as tf\\nfrom tensorflow.keras.utils import normalize\\nimport os\\nimport cv2\\nfrom PIL import Image\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.optimizers import Adam\\nimport glob\\n'' returned non-zero exit status 2."
     ]
    }
   ],
   "source": [
    "%%python –version\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import normalize\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read pathes of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T21:17:54.609697Z",
     "iopub.status.busy": "2023-12-02T21:17:54.606942Z",
     "iopub.status.idle": "2023-12-02T21:17:54.616908Z",
     "shell.execute_reply": "2023-12-02T21:17:54.615522Z",
     "shell.execute_reply.started": "2023-12-02T21:17:54.609638Z"
    }
   },
   "outputs": [],
   "source": [
    "image_directory = '/kaggle/input/modis-dataset/images'\n",
    "mask_directory = '/kaggle/input/modis-dataset/annotations'\n",
    "test_image_directory = '/kaggle/input/d/abdulrahmanmagdy01/test-images/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read names of images in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T21:17:54.629828Z",
     "iopub.status.busy": "2023-12-02T21:17:54.626212Z",
     "iopub.status.idle": "2023-12-02T21:17:54.664739Z",
     "shell.execute_reply": "2023-12-02T21:17:54.663692Z",
     "shell.execute_reply.started": "2023-12-02T21:17:54.629763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/kaggle/input/modis-dataset/images/45.jpg', '/kaggle/input/modis-dataset/images/56.jpg', '/kaggle/input/modis-dataset/images/20.jpg', '/kaggle/input/modis-dataset/images/58.jpg', '/kaggle/input/modis-dataset/images/6.jpg', '/kaggle/input/modis-dataset/images/76.jpg']\n",
      "['/kaggle/input/modis-dataset/annotations/41_GT.png', '/kaggle/input/modis-dataset/annotations/49_GT.png', '/kaggle/input/modis-dataset/annotations/21_GT.png', '/kaggle/input/modis-dataset/annotations/76_GT.png', '/kaggle/input/modis-dataset/annotations/15_GT.png', '/kaggle/input/modis-dataset/annotations/36_GT.png']\n",
      "['/kaggle/input/d/abdulrahmanmagdy01/test-images/test/208.jpg', '/kaggle/input/d/abdulrahmanmagdy01/test-images/test/333.jpg', '/kaggle/input/d/abdulrahmanmagdy01/test-images/test/369.jpg', '/kaggle/input/d/abdulrahmanmagdy01/test-images/test/89.jpg', '/kaggle/input/d/abdulrahmanmagdy01/test-images/test/275.jpg', '/kaggle/input/d/abdulrahmanmagdy01/test-images/test/212.jpg']\n"
     ]
    }
   ],
   "source": [
    "image_names = glob.glob(\"/kaggle/input/modis-dataset/images/*.jpg\")\n",
    "mask_names = glob.glob(\"/kaggle/input/modis-dataset/annotations/*.png\")\n",
    "image_test_names = glob.glob(\"/kaggle/input/d/abdulrahmanmagdy01/test-images/test/*.jpg\")\n",
    "\n",
    "print(image_names[0:6])\n",
    "print(mask_names[0:6])\n",
    "print(image_test_names[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sort names of images in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T21:17:54.672084Z",
     "iopub.status.busy": "2023-12-02T21:17:54.669593Z",
     "iopub.status.idle": "2023-12-02T21:17:54.689300Z",
     "shell.execute_reply": "2023-12-02T21:17:54.688174Z",
     "shell.execute_reply.started": "2023-12-02T21:17:54.672030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/kaggle/input/modis-dataset/images/0.jpg', '/kaggle/input/modis-dataset/images/1.jpg', '/kaggle/input/modis-dataset/images/2.jpg', '/kaggle/input/modis-dataset/images/3.jpg', '/kaggle/input/modis-dataset/images/4.jpg', '/kaggle/input/modis-dataset/images/5.jpg']\n",
      "['/kaggle/input/modis-dataset/annotations/0_GT.png', '/kaggle/input/modis-dataset/annotations/1_GT.png', '/kaggle/input/modis-dataset/annotations/2_GT.png', '/kaggle/input/modis-dataset/annotations/3_GT.png', '/kaggle/input/modis-dataset/annotations/4_GT.png', '/kaggle/input/modis-dataset/annotations/5_GT.png']\n",
      "['/kaggle/input/d/abdulrahmanmagdy01/test-images/test/80.jpg', '/kaggle/input/d/abdulrahmanmagdy01/test-images/test/81.jpg', '/kaggle/input/d/abdulrahmanmagdy01/test-images/test/82.jpg', '/kaggle/input/d/abdulrahmanmagdy01/test-images/test/83.jpg', '/kaggle/input/d/abdulrahmanmagdy01/test-images/test/84.jpg', '/kaggle/input/d/abdulrahmanmagdy01/test-images/test/85.jpg']\n"
     ]
    }
   ],
   "source": [
    "image_names = sorted(image_names, key = lambda x: (len (x), x))\n",
    "mask_names = sorted(mask_names, key = lambda x: (len (x), x))\n",
    "image_test_names = sorted(image_test_names, key = lambda x: (len (x), x))\n",
    "print(image_names[0:6])\n",
    "print(mask_names[0:6])\n",
    "print(image_test_names[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resize and normalization for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T21:17:54.696116Z",
     "iopub.status.busy": "2023-12-02T21:17:54.692870Z",
     "iopub.status.idle": "2023-12-02T21:18:02.828116Z",
     "shell.execute_reply": "2023-12-02T21:18:02.811717Z",
     "shell.execute_reply.started": "2023-12-02T21:17:54.696064Z"
    }
   },
   "outputs": [],
   "source": [
    "images = [cv2.imread(img) for img in image_names]\n",
    "masks = [cv2.imread(mask,0) for mask in mask_names]\n",
    "for i in range(len(images)):\n",
    "    images[i] = cv2.resize(images[i] , (256,256))\n",
    "    images[i] = cv2.normalize(images[i], None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    masks[i] = cv2.resize(masks[i] , (256,256))\n",
    "    masks[i] = cv2.normalize(masks[i], None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    \n",
    "test_images = [cv2.imread(img) for img in image_test_names]\n",
    "for j in range(len(test_images)):\n",
    "    test_images[j] = cv2.resize(test_images[j] , (256,256))\n",
    "    test_images[j] = cv2.normalize(test_images[j], None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T21:18:02.845545Z",
     "iopub.status.busy": "2023-12-02T21:18:02.844472Z",
     "iopub.status.idle": "2023-12-02T21:18:02.864522Z",
     "shell.execute_reply": "2023-12-02T21:18:02.863549Z",
     "shell.execute_reply.started": "2023-12-02T21:18:02.845497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(images))\n",
    "print(len(masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T21:18:02.871243Z",
     "iopub.status.busy": "2023-12-02T21:18:02.867900Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(images)):\n",
    "    masks[i].resize(256,256,1)\n",
    "#     plt.imshow(images[i])\n",
    "#     plt.pause(0.01)\n",
    "#     plt.imshow(masks[i])\n",
    "#     plt.pause(0.01)\n",
    "    r_to_l_img = tf.image.flip_left_right(images[i])\n",
    "    r_to_l_mask = tf.image.flip_left_right(masks[i])\n",
    "#     plt.imshow(r_to_l_img)\n",
    "#     plt.pause(0.01)\n",
    "#     plt.imshow(r_to_l_mask)\n",
    "#     plt.pause(0.01)\n",
    "    images.append(r_to_l_img)\n",
    "    masks.append(r_to_l_mask)\n",
    "#     plt.imshow(images[-1])\n",
    "#     plt.pause(0.01)\n",
    "#     plt.imshow(masks[-1])\n",
    "#     plt.pause(0.01)\n",
    "    u_to_d_img = tf.image.flip_up_down(images[i])\n",
    "    u_to_d_mask = tf.image.flip_up_down(masks[i])\n",
    "#     plt.imshow(u_to_d_img)\n",
    "#     plt.pause(0.01)\n",
    "#     plt.imshow(u_to_d_mask)\n",
    "#     plt.pause(0.01)\n",
    "    images.append(u_to_d_img)\n",
    "    masks.append(u_to_d_mask)\n",
    "#     plt.imshow(images[-1])\n",
    "#     plt.pause(0.01)\n",
    "#     plt.imshow(masks[-1])\n",
    "#     plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert data to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = np.array(images)\n",
    "mask_dataset = np.array(masks)\n",
    "test_image_dataset = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=80\n",
    "i=0\n",
    "for i in range(1):    #len(image_dataset)\n",
    "    path = 'E:\\\\study\\\\faculty of computer sience\\\\Graduation project\\\\Marwa task\\\\images\\\\80.jpg'\n",
    "    r_to_l_img = tf.image.flip_left_right(image_dataset[i])\n",
    "    print(type(image_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dataset.resize(80,256,256,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print data shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Image data shape is: \", image_dataset.shape)\n",
    "print(\"Mask data shape is: \", mask_dataset.shape)\n",
    "print(\"Test_Image data shape is: \", test_image_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize image and its mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=78\n",
    "plt.imshow(images[i])\n",
    "plt.pause(0.01)\n",
    "plt.imshow(masks[i] , cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = image_dataset\n",
    "Y = mask_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build our U-net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Unet by dividing encoder and decoder into blocks\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Activation, MaxPool2D, Concatenate\n",
    "\n",
    "\n",
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)   #Not in the original network. \n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)  #Not in the original network\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "#Encoder block: Conv block followed by maxpooling\n",
    "\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p   \n",
    "\n",
    "#Decoder block\n",
    "#skip features gets input from encoder for concatenation\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "#Build Unet using the blocks\n",
    "def build_unet(input_shape, n_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b1 = conv_block(p4, 1024) #Bridge\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    if n_classes == 1:  #Binary\n",
    "      activation = 'sigmoid'\n",
    "    else:\n",
    "      activation = 'softmax'\n",
    "\n",
    "    outputs = Conv2D(n_classes, 1, padding=\"same\", activation=activation)(d4)  #Change the activation based on n_classes\n",
    "    print(activation)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = image_dataset.shape[1]\n",
    "IMG_WIDTH  = image_dataset.shape[2]\n",
    "IMG_CHANNELS = image_dataset.shape[3]\n",
    "\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call model and print his summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_unet(input_shape, n_classes=1)\n",
    "model.compile(optimizer=Adam(learning_rate = 1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = model.fit(X, Y, \n",
    "                    batch_size = 16, \n",
    "                    verbose=1, \n",
    "                    epochs=200,  \n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_image_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model = model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visaulize our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "plt.imshow(test_images[i])\n",
    "plt.pause(0.01)\n",
    "plt.imshow(predict_model[i],cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2815097,
     "sourceId": 4856192,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2832875,
     "sourceId": 4885648,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2839868,
     "sourceId": 5658001,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30357,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
